<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Looking Through the Oculus Rift : Example and code about how to look through the Oculus Rift with webcams | Virtual Reality, Augmented Reality and Gesture Interaction">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Looking Through the Oculus Rift</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/federico-mammano/Looking-Through-Oculus-Rift">View on GitHub</a>

          <h1 id="project_title">Looking Through the Oculus Rift</h1>
          <h2 id="project_tagline">Example and code about how to look through the Oculus Rift with webcams | Virtual Reality, Augmented Reality and Gesture Interaction</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/federico-mammano/Looking-Through-Oculus-Rift/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/federico-mammano/Looking-Through-Oculus-Rift/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h2>
<a id="introduction" class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h2>

<p><br>
The purpose of these examples is to provide a practical guide and an effective starting point regarding the ambitious and real possibilities to extend the way of using the Oculus Rift, gathering together Virtual Reality, Augmented Reality and Gesture Interaction in a unique project.</p>

<p>Virtual Reality (VR) is all about the creation of a virtual world that users can interact with. Users are isolated from the real world while immersed in a full synthetic environment, as far as the immersive experience is achieved by the wearing of a VR helmet (e.g.: Oculus Rift).</p>

<p>On the other hand, Augmented Reality (AR) blends virtual reality contents with the real world. As a result, users can interact with virtual contents while continuing to be in touch with the real life around them. This experience is achieved by the wearing of AR glasses (e.g.: Google Glasses).</p>

<p>VR seems to be more B2C and entertainment oriented (e.g.: Video Games) while AR might have a wider spectrum of use and a more commercial success because it does not completely take users out of the real world. VR HMDs have a worse wearing factor, require more computing power, however they can offer a better immersive surreal experience compared to AR HUDs. By the way, both VR and AR appear to be similar as far as the aim of immersing the user is concerned.</p>

<p>Technically speaking, the main difference between the two systems seems to be a transparency mask issue. VR scenes are completely opaque over the entire display (i.e. you cannot see the real world around you). AR glasses are transparent (you see the real environment) and pixels where virtual contents are drawn have an opacity value in order to overwrite the real world light information. From this point of view, VR is simply a transparency mask limit case of AR, where transparency has a null value over the entire display. </p>

<p>Often it seems that VR and AR are two different worlds that do not overlap. But what if we imagine VR and AR on the same next generation device? Why do not have a unique system that could provide both AR and VR experiences? Well, it is not so simple as it looks like ...</p>

<p>The visionary device would be more similar to AR glasses. It would be wireless, lightweight and with a nice wearing design and charm for walking on the street and being able to see the real world. It would have a wide field of view and an ultra-low latency display to offer a great immersive experience when playing a video game or watching a movie. This next generation mobile device would also have some sensors (e.g.: Depth/ToF camera, microphone, ...) to easily interact with.<br> 
Like for mobile devices, next-gen apps would deal with the transparency mask and device buffers, offering a mixed reality experience or completely isolating the user from the real life.</p>

<p>The issue is to completely cover light information coming from the real environment in a specific area of the glasses with the virtual contents and being able to blend the two worlds from 0% up to 100%. If the lenses wouldn't be able to be fully opaque, the sum of the virtual world projected light and the real world light would produce a virtual image ghosting over the real life.</p>

<p>Even if less attractive and still with a lot of issues, an effective and low-cost alternative to start your own VR/AR experience on a same device, would be to add a couple of eyes (camera sensors) to an Oculus Rift in order to look beyond the HMD. </p>

<p>As far as "issues" are concerned, I report the main of them here below, with the purpose to share what I am talking about.</p>

<p><strong>Movement</strong>. Even if you have performant webcams (e.g.: 60fps), the FPS still matter. And even if I have split the webcam management from the rest of functionalities, with a multi-threaded approach, in order to avoid lack of performances, while waiting every frame to get information from cameras, you could still note a minimal delay between your movements and the following real-time video, that you wouldn’t have in real life. Moreover, even if you have a 60fps webcam (i.e. a shutter speed of about 1/60), you would still notice the motion blur effect, that you would not in the real life.</p>

<p><strong>Pixels</strong>. Even if you have high resolution webcams (with low-res sensors you would worsen with a stretched blocky effect), the central grid of pixels of the Oculus display is still remarkable and this reduces the experience of directly looking the real world. Moreover, you cannot struggle against ISO of your camera sensor. As far as the Rift is a wired device, most of the time you would be in a low-light condition, that implies a high sensibility mde of the sensor and as a result, a lot of noise all over the frame. On top of that, the dynamic range of the webcam is not the same of  the eye (about 10-14 f-stops), however this issue seems to be less annoying than the motion blur effect.</p>

<p>Yes, many issues ... but it works!<br>
And it is an easy-to-do system that can integrate Virtual Reality, Augmented Reality and Gesture Interaction all in one.
<br><br><br></p>

<h2>
<a id="do-it-yourself" class="anchor" href="#do-it-yourself" aria-hidden="true"><span class="octicon octicon-link"></span></a>Do It Yourself</h2>

<p>This project has been designed to work with one or two webcams. In the early testing phase you can just use one webcam, even if I recommend to use two webcams for a stereoscopic and more involving experience. Place the webcams in front of your Oculus Rift as in the Image 1. Pay attention to not cover too much the IR leds of the rift.
I positioned the two webcams at the interpupillary distance (about 62-66 cm) and I connected  them with a shifting bar (A on Image 1) that can manually rotate the devices (B on Image 1), simulating the change of eye focusing distance. To replace this manual task by an automated system you should have internal cameras recognising the pupil movements, identifying the focusing distance and reproducing the same rotation on external webcams. Nevertheless, for simplicity, you can keep them fixed and forward oriented (i.e. far focusing).</p>

<p>The Oculus field of view, normally, is wider than the webcam. Even if you can customize the project for any FOV through parameter values (cf. <em>Setup</em> of <em>Example 1</em>), I recommend to choose a webcam with a field of view as much similar as the Oculus FOV. I personally used two 120° ultra wide angle lens webcam (Genius WideCam F100 Full HD). </p>

<p>As far as each eye of the Oculus Rift has a display resolution of 960x1080 pixel (vertical format), if you have a landscape webcam format, place the cameras vertically in order to fill the frame in the better way with a good pixel density ratio. The bigger the webcam resolution the better the final image (e.g.: resizing from a Full HD 1080x1920 webcam frame into a 960x1080 Oculus frame).
<br></p>

<p><img src="images/Image1.jpg" alt="Oculus Rift with two webcams">
<br>
<strong>Image 1</strong>. <em>Oculus Rift with two webcams vertically oriented. Shifting the connecting bar towards right (A), it would progressively rotate the left webcam clockwise and the right webcam counterclockwise (B) – near focusing. Pulling the bar (A) in the original position, it would bring the two webcam back in their looking forward original position – far focusing.</em>
<br><br><br></p>

<h2>
<a id="example-1" class="anchor" href="#example-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Example 1</h2>

<p>This example has been based upon the original Oculus Room Tiny project provided with the Oculus SDK in order to give the opportunity to everyone to immediately play with the code in a very basic application and focus on things that matter. With the aim to facilitate the use I have also provided the project both with DirectX and OpenGL functionalities. Note that OpenGL works, but could present some issues.</p>

<p>As soon as you compile and execute the application, the video streaming from the webcams will be displayed on your Oculus Rift delivering the right webcam content to your right eye and left webcam to your left eye, as shown in the Image 2. If you have only one webcam (Cyclops mode), the video will be reproduced for both eyes, but you won’t have a stereoscopic effect.</p>

<p>Pressing the key [X] will switch from the looking-through vision to the VR world of the RoomTiny project in which there are two semi-transparent posters with the webcam videos (cf. Image 3).
<br></p>

<p><img src="images/Image2.jpg" alt="Looking through the Rift mode">
<br>
<strong>Image 2</strong>. <em>The left webcam is projected into the left eye and the right webcam to the right eye – Looking-through mode.</em>
<br></p>

<p><img src="images/Image3.jpg" alt="VR mode">
<br>
<strong>Image 3</strong>. <em>The VR world of the RoomTiny with the two semi-transparent pannels showing left and right videos in real-time.</em>
<br><br></p>

<h3>
<a id="setup" class="anchor" href="#setup" aria-hidden="true"><span class="octicon octicon-link"></span></a>Setup</h3>

<p>You will find the Visual Studio (2010, 2012 and 2013) global project in the folder <em>Samples</em> and the specific example files in the folder <em>Samples/OculusRoomTiny</em>.</p>

<p>This project takes advantage of the OpenCV library (Version 2.4.10 has been used). <a href="http://docs.opencv.org/trunk/doc/tutorials/introduction/windows_visual_studio_Opencv/windows_visual_studio_Opencv.html#windows-visual-studio-how-to">Click here</a> to learn how to install it.</p>

<p>If you would like to change the OpenCV version, remeber  to change the <em>Linker/Input/Additional Dependencies</em>:</p>

<ul>
<li>Debug versions: <em>opencv</em> *<em>2410d.lib</em>
</li>
<li>Release versions: <em>opencv</em> * <em>2410.lib</em><br>
</li>
</ul>

<p>with the correct dependencies.
<br><br></p>

<p><em><strong>Win32_RoomTiny_Main.cpp</strong></em></p>

<hr>

<p>In this file you can modify these c++ macro parameters:</p>

<p><code>#define SDK_RENDER 1</code><br>
This option will give you the opportunity to choose whether to use the Oculus SDK to make the Rift distortion for you or if do it through the application code. This works both with DirectX and OpenGL.</p>

<p><code>#define RENDER_OPENGL 1</code><br>
This option will give you the opportunity to choose whether to use DirectX or OpenGL to render the scene.
<br><br></p>

<p><em><strong>Win32_WebCam.h</strong></em><br></p>

<hr>

<p>In this file you can modify these c++ macro parameters:</p>

<p><code>#define WEBCAM_NB 2</code><br>
This option will tell to the application how many webcams you have. This value can be 1 if you have only a webcam (cyclops/non-stereo mode) or 2 if you have two webcams (stereoscopic mode) as shown in the Image 1.</p>

<p><code>#define WEBCAM_0_DEVICE_NUMBER 0</code><br>
This option will tell to the first (or unique if you have only one) webcam from which connected physical device to read the video information.<br>
Note: If you have more than one webcam connected to your computer, increase this number until you will find your left eye webcam.</p>

<p><code>#define WEBCAM_0_VERT_ORIENTATION true</code><br>
This option will tell to the first (or unique if you have only one) webcam if it positioned in the landscape mode (<em>false</em>) or in the portrait mode (<em>true</em>). Webcams in the Image 1 are set in the portrait mode.</p>

<p><code>#define WEBCAM_0_HMD_FOV_RATIO 1.0f</code><br>
This option will tell to the first (or unique if you have only one) webcam what is the ratio between the physical webcam diagonal field of view and the relative Rift FOV (approximately 100°). If your webcam has approximately the same Rift FOV, this value can be 1.0f.<br>
Note: Even if I have mounted two 120° ultra-wide webcams (therefore a bigger FOV than the Rift), I set this value to 2/3 = 0.67. This reduce the immersion feeling, on the other hand it gives a more realistic feeling regarding the distances. Remember that the webcams are shifted about 5-10 cm in front of your eyes, therefore if you would like to interact with your hand and the real life through the webcams, everything appear to be closer than in reality, and so a zoom correction factor can help. If you are generally looking far from you and the webcams are forward looking, this aspect can be neglected.</p>

<p>If you have only one webcams, don’t care about the following parameters. Otherwise if you have two webcams, you should configure the right eye webcam as explained for the previous one.</p>

<pre><code>#define WEBCAM_1_DEVICE_NUMBER     1
#define WEBCAM_1_VERT_ORIENTATION  true
#define WEBCAM_1_HMD_FOV_RATIO     1.0f
</code></pre>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Looking Through the Oculus Rift maintained by <a href="https://github.com/federico-mammano">federico-mammano</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-59946463-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>


  </body>
</html>
